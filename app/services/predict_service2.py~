from ultralytics import YOLO
from app.services.color_service import ColorCheck
from app.services.config_service import load_config
from app.services.data_services.data_service import DataManager
from lib.deepsort.tracking import run
import uuid
import time
from pathlib import Path
import datetime
import csv
import pandas as pd
import numpy as np
import cv2
from mss import mss
from PIL import Image
import traceback


manager = DataManager()
colorC = ColorCheck()
config = load_config()
model_pred_clothing = YOLO(config.get("AI_MODEL_PATH")+config.get("AI_MODEL_NAME"))
main_model_path =config.get("AI_MODEL_PATH")+'yolo11m.pt'

data = r"E:\ALL_CODE\python\fashion-project\lib\deepsort\data\coco.yaml"
CLASS_NAMES_CLOTHING = ['short sleeve top', 'long sleeve top', 'short sleeve outwear', 'long sleeve outwear', 'vest', 'sling', 'shorts', 'trousers', 'skirt', 'short sleeve dress', 'long sleeve dress', 'vest dress', 'sling dress']


def prediction(xyxy,identities,frame,conut_frame):
    try:    
        xp1,yp1,xp2,yp2 = xyxy
        crop = frame[yp1:yp2, xp1:xp2]
        results= model_pred_clothing.predict(crop, verbose=False)[0]
        clothing_list=[]
        object_data = { 
                        'objectin':False,
                        'frame':conut_frame,
                        'x_person': xp1, 
                        'y_person': yp1,
                        'w_person': xp2 - xp1, 
                        'h_person': yp2 - yp1, 
                        'track_id':identities,
                    }
        if results:
            boxes = results.boxes
            all_obj = results.boxes.cls.cpu().numpy()
            all_conf = results.boxes.conf.cpu().numpy()
            if len(all_obj) > 2:
                s=''
                for i,cls_ in enumerate(all_obj):
                    s+=f'ID: \033[93m{identities}\033[0m class: \033[92m{92mmodel_pred_clothing.names[cls_]}\033[0m | conf: \033[91m[{round(all_conf[i],2)}]\033[0m | '
                print(s)
                print("------------------------------------------------------------------------------------------------------")
            for box in boxes:
                xc1,yc1,xc2,yc2 = map(int, box.xyxy[0].cpu().numpy())
                cls = int(box.cls.cpu().item())        # class index เป็น int
                conf = float(box.conf.cpu().item())    # confidence เป็น float
                crop_clothing = crop[yc1:yc2 ,xc1:xc2]
                crop_clothing = np.ascontiguousarray(crop_clothing)
                list_color = colorC.get_color_percentage_with_threshold(crop_clothing)
                clothing_list.append({ 
                                        **object_data,
                                        'objectin':True,
                                        'predict_id': str(uuid.uuid4()), 
                                        'class_id': cls, 
                                        'class_name': model_pred_clothing.names[cls], 
                                        'confidence': round(conf, 2), 
                                        'x_clothing': xc1,
                                        'y_clothing': yc1,
                                        'w_clothing': xc2 - xc1,
                                        'h_clothing': yc2 - yc1,
                                        'mean_color_bgr': list_color
                                    })
        else:
            clothing_list.append({ 
                                    **object_data,
                                    'predict_id': str(uuid.uuid4()), 
                                    'class_id': 'undifined', 
                                    'class_name': 'undifined', 
                                    'confidence': 0, 
                                    'x_clothing': 0,
                                    'y_clothing': 0,
                                    'w_clothing': 0,
                                    'h_clothing': 0,
                                    'mean_color_bgr': []
                                })

        return clothing_list
    except Exception as e:
        print(f'\033[91m[detection]\033[0m is error : {e}')
        traceback.print_exc()
def fill_the_space(data):
    try:
        df = pd.DataFrame(data)
        row_latest = None
        for row in df.itertuples():
            if row.class_id != True:
                row_latest = row
            else:
                if row_latest is not None:
                    df.loc[row.Index]['objectin'] == True
                    df.loc[row.Index]['class_id'] == row_latest.class_id
                    df.loc[row.Index]['class_name'] == row_latest.class_name
                    df.loc[row.Index]['confidence'] == row_latest.confidence
                    df.loc[row.Index]['x_clothing'] == row_latest.x_clothing
                    df.loc[row.Index]['y_clothing'] == row_latest.y_clothing
                    df.loc[row.Index]['w_clothing'] == row_latest.w_clothing
                    df.loc[row.Index]['h_clothing'] == row_latest.h_clothing
                    df.loc[row.Index]['mean_color_bgr'] == row_latest.mean_color_bgr
        return df

    except Exception as e:
        print(f"[fill_the_space] is erroe : {e}")
        traceback.print_exc()



def get_result_csv(dir, detect_all, type_of_detection):
        date_str = datetime.datetime.now().strftime('%Y%m%d')
        output_dir = Path(dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        if detect_all:
            base_name = output_dir / f"results_{type_of_detection}_{date_str}_1.json"
            if not Path(base_name).exists():
                return str(base_name)
            counter = 2
            while True:
                new_name = output_dir /  f'results_{type_of_detection}_{date_str}_{counter}.json'
                if not Path(new_name).exists():
                    return str(new_name)
                counter = counter + 1
        else:
            files = [f for f in [p.name for p in output_dir.iterdir()] if f.startswith(f'results_{type_of_detection}_{date_str}')]
            if files:
                return output_dir / sorted(files)[(-1)]
        return str(output_dir / f'results_{type_of_detection}_{type_of_detection}.json')

def get_video_files( folders):
    video_files = []
    for folder in folders:
        print(folder)
        for file in Path(folder).rglob("*"):
            if file.suffix.lower() in (".mp4", ".avi", ".mov"):
                video_files.append(str(file))
    print(f"[get_video_files] พบ {len(video_files)} ไฟล์")
    return video_files


def write_log( filename, process_id, process_type):
    try:
        log_path = Path(config['PROCESSED_LOG'])
        
        # สร้างโฟลเดอร์ถ้ายังไม่มี
        if log_path.parent:
            log_path.parent.mkdir(parents=True, exist_ok=True)

        headers = [
            'predict_id', 'process_id', 'filename', 'datetime',
            'person_detection_result_path', 'clothing_detection_result_path',
            'save_result_name', 'process_type'
        ]

        # เขียน header ถ้าไฟล์ยังไม่ถูกสร้าง
        if not log_path.exists():
            with log_path.open('w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                writer.writerow(headers)

        # เขียน log ใหม่ (append)
        with log_path.open('a', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow([
                process_id,
                str(uuid.uuid4()),
                filename,
                datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                config['JSON_RESULT_PREDICT_PERSON'],
                config['JSON_RESULT_PREDICT_CLOTHING'],
                'detect',
                process_type
            ])
    except Exception as e:
        print(f'\033[91m[write_log]\033[0m is error : {e}')

def get_wh(source):
    """
    Return (width, height) of the source.
    Supports image, video, webcam (numeric), URL stream, screenshot.
    """
    try:
        IMG_FORMATS = ['jpg','jpeg','png','bmp','tif','tiff','dng','webp','mpo']
        VID_FORMATS = ['mp4','mov','avi','mkv','wmv','flv','mpg','mpeg','ts']
        source = str(source)
        is_file = Path(source).suffix[1:].lower() in (IMG_FORMATS + VID_FORMATS)
        is_url = source.lower().startswith(('rtsp://','rtmp://','http://','https://'))
        webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)
        screenshot = source.lower().startswith('screen')

        if is_file:  # Image or video file
            suffix = Path(source).suffix[1:].lower()
            if suffix in IMG_FORMATS:  # Image
                img = Image.open(source)
                w, h = img.size
            else:  # Video
                cap = cv2.VideoCapture(source)
                w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                cap.release()

        elif webcam:  # Webcam or stream
            cap = cv2.VideoCapture(int(source) if source.isnumeric() else source)
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()

        elif screenshot:  # Screen capture
            with mss() as sct:
                monitor = sct.monitors[0]  # full screen
                w = monitor['width']
                h = monitor['height']

        elif is_url:  # URL stream (not a file)
            cap = cv2.VideoCapture(source)
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()

        else:
            raise ValueError(f"Unknown source type: {source}")

        return w, h
    except Exception as e:
        print(f"[get_wh] is error : {e}")

def predict_ctrl(data_batch,filename,source):
    try:
        
        h, w = get_wh(source)
        data = pd.DataFrame(data_batch, columns=["bbox_xyxy", "identities", "ims", "frame"])
        data["identity_key"] = data["identities"].apply(lambda x: x[0])
        datagroup = data.groupby("identity_key")
        all_result = pd.DataFrame()
        for group_value, group_df in datagroup:
            track_gruop = []
            for row in group_df.itertuples():
                bbox_xyxy   = row.bbox_xyxy
                ims         = row.ims
                count_frame = row.frame
                identity_key = row.identity_key
                for i, box in enumerate(bbox_xyxy):
                    track_gruop.extend(prediction(box,identity_key,ims,count_frame))
            if track_gruop is not None:
                df = pd.DataFrame(track_gruop)
                df['filename'] = filename
                df['w_vid'] = w
                df['h_vid'] = h
                # tuned = fill_the_space(df)
                all_result = pd.concat([df, all_result], ignore_index=True)  
        return all_result

    except Exception as e:
        print(f'\033[95m[predict_ctrl]\033[0m is error : {e}')
        traceback.print_exc()



def processing_videos():
        
        try:
            process_status:bool = False
            process_id = str(uuid.uuid4())
            dir = config.get('RESULTS_PREDICT_DIR')
            path_to_save = get_result_csv(dir + 'clothing_detection', True, 'clothing_detection')
            print('see result at :\033[93m',path_to_save,'\033[0m')
            video_files = get_video_files([config['VIDEO_PATH']])
            if len(video_files) == 0:
                print('no video')
                return
            
            for video in [video_files[0]]:
                
                start_track = time.perf_counter()
                filename = Path(video).name
                print(f'[▶] Processing: {video}')

                predict = run(weights=main_model_path,source= video,data=data,classes=0,pred_clothing=True)

                if not predict.empty:
                    num_rows = predict.shape[0]
                    print('predicted data ',num_rows)
                    predict['process_id'] = process_id
                    manager.update_result_to_json(path_to_save,predict.to_dict(orient='records'))
                    write_log(filename, process_id, 'normal_detection')
                    track_time = time.perf_counter() - start_track
                    print(track_time)
                    process_status=True
            if process_status:
                print('predict success!!')
            else:
                print('process detection fail!!')
        except Exception as e:
            print(f'[processing_videos] is error : {e}')
            # traceback.print_exc()

if __name__ == 'main':
    processing_videos()
